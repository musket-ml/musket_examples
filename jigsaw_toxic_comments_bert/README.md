![Logo](https://storage.googleapis.com/kaggle-media/competitions/jigsaw/003-avatar.png)

# Musket example for Toxic Comment Classification Challenge

This is Musket example for [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/)

Given competition is aimed at building a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. 

* Ensure you have Python 3.6, as well as Musket and Kaggle python packages with their dependencies installed, Keras installed and configured
* In experiment root folder - `quora-insincere-questions` - in command line type `musket fit -d`. `-d` tells Musket to download dependencies - Toxic Comment Classification Challenge dataset in this case - before launching experiments. If you have more than one card available - don't forget to add `--num_gpus=N` parameter, where N is an amount of your available devices

## Launching from DS IDE

You can also edit and launch this example using our [DS IDE](https://musket-ml.github.io/webdocs/ide/getting_started/)

## Modules and used capabilities

### datasets.py

This file contains dataset definions - methods decorated with `@datasets.dataset_provider(origin=...,kind=...)`. Such definitions can be generated by IDE based on a dataset


